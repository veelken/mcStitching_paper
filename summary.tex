\section{Summary}
\label{sec:summary}

The production of MC samples of adequate size is often a challenge in modern HEP experiments,
due to the computing resources required to produce and store such samples.
This is particularly true for experiments at the CERN LHC,
firstly because of the large cross sections of processes of interest (such as Drell-Yan production, the production of $\PW$ bosons, and the production of top quark pairs)
and secondly because of the large luminosity delivered by the LHC.

In this paper we have focused on the case that the MC samples have already been produced
and we have presented a procedure that allows to reduce the statistical uncertainties 
by combining MC samples which overlap in PS.
The procedure is based on applying suitably chosen weights to the simulated events.
We refer to this procedure as ``stitching''.

The formalism is general enough to be applied in various different use-cases.
In physics analyses, the stitching procedure allows to reduce the statistical uncertainties in particular in the tails of distributions.
Two examples have been presented that document the use of the stitching procedure in physics analyses performed by the CMS experiments during LHC Runs $1$ and $2$.
We have then extended the formalism to cover the case of estimating trigger rates at the HL-LHC,
where up to $200$ simultaneous $\Pp\Pp$ collisions are expected per crossing of the proton beams.
The distinguishing feature of this use-case is that the same physics process, 
inelastic $\Pp\Pp$ scattering interactions in which a transverse momentum $\pThat$ is exchanged between the protons,
may occur in the ``hard-scatter'' interaction and in ``pileup'' interactions.
